# -*- coding: utf-8 -*-
"""Submission_Predictive_Analytics

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lX0vLX9psHxYXgyw8tidIxtAzmyUf0MK

# **Proyek Pertama: Predictive Analytics - Klasifikasi Penyakit Diabetes**

**Nama: Muhammad Rizqi Azhari**

**Username Dicoding: rizqimrazhari**

# **1. Pendahuluan**

Tahap ini berisi overview proyek, deskripsi dataset, instalasi dependensi, dan import library yang diperlukan.

## **Overview**

**Rumusan Masalah**

- Algoritma atau model machine learning mana yang paling efektif untuk memprediksi diabetes pada dataset ini?
- Faktor-faktor apa saja yang paling signifikan dalam memprediksi apakah seseorang akan menderita diabetes?

**Tujuan**

- Membangun dan mengoptimalkan model machine learning yang dapat memprediksi kemungkinan seseorang menderita diabetes dengan akurat.
- Menemukan dan memahami faktor-faktor utama yang berkontribusi terhadap risiko diabetes, seperti kadar glukosa, insulin, BMI, dan umur.

## **Dataset**

Pima Indians Diabetes Database:

https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database

**Dataset Content**

Deskripsi fitur:
- **Pregnancies**: Jumlah kehamilan yang dialami oleh individu wanita.
- **Glucose**: Kadar glukosa dalam darah yang diukur setelah periode puasa.
- **BloodPressure**: Tekanan darah diastolik, yaitu tekanan darah saat jantung beristirahat di antara denyut.
- **SkinThickness**: Ketebalan lipatan kulit trisep yang diukur dalam milimeter.
- **Insulin**: Kadar insulin serum dua jam setelah tes toleransi glukosa.
- **BMI**: Rasio berat badan (kg) terhadap tinggi badan (m^2).
- **DiabetesPedigreeFunction**: Skor yang memberikan informasi tentang riwayat keluarga dan kemungkinan faktor genetik dalam diabetes.
- **Age**: Usia individu dalam tahun.
- **Outcome**: Indikator binari yang menunjukkan apakah individu tersebut menderita diabetes atau tidak (1: menderita diabetes, 0: tidak menderita diabetes).

## **Install Dependencies & Import Libraries**
"""

# Install Kaggle API
!pip install kaggle -q kaggle

# Install Optuna for Hyperparameter Tuning
!pip install optuna

# Install XGBoost for ensemble learning model
!pip install xgboost

# Commented out IPython magic to ensure Python compatibility.
# Import reuqired libraries

# Data loading
import pandas as pd
import numpy as np

# Data visualization
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import plotly.express as px

# Machine Learning & Statistics
from scipy.stats import f_oneway
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
import optuna

# Ignore warnings
import warnings
warnings.filterwarnings('ignore')

"""# **2. Data Understanding**

Pada tahap ini dilakukan proses memuat data, memahami informasi dalam data, dan melakukan Exploratory Data Analysis (EDA) untuk menganalisis karakteristik, menemukan pola maupun anomali.

## **2.1. Load Dataset**
"""

# Membuat direktori baru bernama kaggle
!rm -rf ~/.kaggle && mkdir ~/.kaggle/

# Menyalin berkas kaggle.json pada direktori aktif saat ini ke direktori kaggle
!mv kaggle.json ~/.kaggle/kaggle.json

# Mengubah permission berkas
!chmod 600 ~/.kaggle/kaggle.json

# Download dataset
!kaggle datasets download -d uciml/pima-indians-diabetes-database

# Ekstrak berkas zip
!unzip /content/pima-indians-diabetes-database.zip

# Melihat 5 data teratas
df = pd.read_csv('diabetes.csv')
df.head()

"""## **2.2. Exploratory Data Analysis (EDA)**

### **Data Description**
"""

# Melihat informasi tipe data
print(df.info())

# Melihat dimensi dataset
print("\n",df.shape)

"""Dataset berisi 768 baris dan 9 kolom."""

# Melihat sebaran statistik data
df.describe().T

"""### **Data Cleaning / Wrangling**"""

# Check missing values
df.isna().sum()

# Check duplicate values
df.duplicated().sum()

"""Tidak ada data duplikat maupun kosong."""

# Membuat salinan dataframe
df_before = df.copy()

sns.pairplot(df_before, diag_kind='kde')

# Outlier detection using boxplot / IQR
df.plot(kind='box', layout=(3, 3), figsize=(15,10), subplots=True, sharex=False, sharey=False)
plt.show()

"""Terdapat outliers pada beberapa fitur"""

# Visualisasi box plot sebelum cleaning
columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']

for col in columns:
  fig = px.box(df_before, x=[col], title=f'Box Plot dari {col} sebelum cleaning')
  fig.show()

# Handling outliers using IQR
def handle_outliers_iqr(df, column):
    """
    Menangani outliers dengan cara mengganti nilai outliers agar tidak melebihi batas atas dan batas bawah.

    Parameters:
        df (DataFrame): DataFrame yang berisi data.
        column: Kolom atau fitur dari DataFrame yang ingin dibersihkan

    Returns:
        df (DataFrame): DataFrame yang telah dimodifikasi dengan outliers yang disesuaikan nilainya.
        outliers (DataFrame): DataFrame yang berisi outliers yang telah diidentifikasi dan disesuaikan nilainya.
    """
    # Calculate first quartile (Q1) and third quartile (Q3)
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)

    # Calculate IQR (Interquartile Range)
    IQR = Q3 - Q1

    # Calculate lower and upper bounds for outliers detection
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Identify outliers
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]

    # Handle outliers by capping them to the lower and upper bounds
    df.loc[df[column] < lower_bound, column] = lower_bound
    df.loc[df[column] > upper_bound, column] = upper_bound

    # Return the modified DataFrame and the outliers removed
    return df, outliers

"""Data outliers tidak di drop, melainkan hanya diganti nilainya agar tidak melebihi batas atas dan batas bawah."""

# Handle outliers di kolom tertentu
# Visualisasi box plot sebelum cleaning
columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']

for col in columns:
  handle_outliers_iqr(df, col)

# Visualisasi box plot setelah cleaning
columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']

for col in columns:
  fig = px.box(df, x=[col], title=f'Box Plot dari {col} setelah cleaning')
  fig.show()

# Melihat dimensi data setelah dibersihkan
df.shape

"""### **Univariate Analysis**"""

# Melihat distribusi data setelah cleaning
df.hist(figsize=(10, 10))
plt.show()

"""Kebanyakan fitur memiliki distribusi data yang condong ke kiri (left-skewed).

### **Bivariate Analysis**
"""

def anova(df, feature_1, feature_2):
    """
    Melakukan analysis of variance (ANOVA) dengan membandingkan dua fitur dalam DataFrame.

    Parameters:
        df (DataFrame): DataFrame yang berisi data.
        feature1 (str): Nama fitur pertama yang ingin dianalisis.
        feature2 (str): Nama fitur kedua yang ingin dianalisis.

    Returns:
        None
    """
    F_statistic = (f_oneway(df[feature_1], df[feature_2])[0])
    p_value = (f_oneway(df[feature_1], df[feature_2])[1])

    print(f"Hasil ANOVA antara {feature_1} dan {feature_2}")
    print("Nilai F:", F_statistic)
    print("Nilai p:", p_value)

# Melakukan analysis of variance (ANOVA) satu arah
anova(df, 'Outcome', 'Glucose')
print()
anova(df, 'Outcome', 'Insulin')
print()
anova(df, 'Outcome', 'Age')
print()
anova(df, 'Glucose', 'Insulin')

"""Hasil ANOVA menunjukkan nilai p yang sangat kecil, ini menunjukkan bahwa H0 (tidak ada hubungan antar fitur) terbantahkan.

### **Multivariate Analysis**
"""

# Melihat korelasi antar fitur menggunakan pairplot
sns.pairplot(df, diag_kind='kde')
plt.show()

# Correlation matrix / heatmap untuk melihat korelasi antar fitur
plt.figure(figsize=(16,8))
sns.heatmap(df.corr(), annot=True, cmap=plt.cm.plasma)
plt.show()

"""Dari matriks korelasi, dapat dilihat fitur-fitur yang memiliki pengaruh signifikan terhadap diabetes adalah Glucose, BMI dan Age. Selain itu, Insulin juga memiliki pengaruh terhadap kadar Glucose.

# **3. Data Preprocessing**

Tahap ini bertujuan untuk mempersiapkan data sebelum masuk ke tahap pengembangan model Machine Learning.

## **Train Test Split**
"""

X = df.drop(columns=['Outcome'])
y = df['Outcome']

print(X.shape)
print(y.shape)

"""Karena ukuran data yang kecil, maka ditetapkan porsi data untuk training dan testing masing-masing 90% dan 10%."""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)

print(f'Jumlah data training: {len(X_train)}')
print(f'Jumlah data testing: {len(X_test)}')

print(X_train)
print("\n=========================================================================\n")
print(X_test)

"""## **Scaling / Normalisasi**"""

# Feature scaling menggunakan MinMaxScaler
scaler = MinMaxScaler()
columns = X_train.columns

X_train.reset_index(drop=True, inplace=True)
X_test.reset_index(drop=True, inplace=True)

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train_scaled = pd.DataFrame(X_train, columns=columns)
X_test_scaled = pd.DataFrame(X_test, columns=columns)

print(X_train_scaled)
print("\n=========================================================================\n")
print(X_test_scaled)

"""# **4. Modeling**

Algoritma yang akan dipakai:
1. Logistic Regression
2. Support Vector Machine (SVM)
3. Extreme Gradient Boosting (XGBoost)

Metrik yang digunakan adalah Akurasi, Precision, Recall, dan F1-score, namun metrik yang menjadi prioritas adalah Recall karena kita ingin meminimalkan false negative (FN), artinya kita ingin memastikan bahwa semua kasus diabetes yang sebenarnya positif diidentifikasi dengan benar.

## **Base Model**
"""

# Inisialisasi model
log_reg = LogisticRegression()
svm = SVC()
xgb = XGBClassifier()

def evaluate_skf(model, X, y, n_splits=10, random_state=42, verbose=True):
    """
    Evaluasi model dengan Stratified K-Fold Cross-Validation dan menghitung metrik kinerja.

    Parameters:
        model: estimator
            Model machine learning yang akan dilatih dan dievaluasi.
        X: array-like, shape (n_samples, n_features)
            Fitur input.
        y: array-like, shape (n_samples,)
            Target output.
        n_splits: int, optional (default=10)
            Jumlah lipatan (folds) untuk cross-validation.
        random_state: int, optional (default=42)
            Seed untuk pengacakan dalam cross-validation.
        verbose: bool, optional (default=True)
            Jika True, hasil evaluasi tiap fold akan ditampilkan.

    Returns:
        dict: Rata-rata metrik kinerja dari semua lipatan
    """
    # Membuat objek StratifiedKFold untuk cross-validation dengan stratifikasi
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)

    # Inisialisasi list untuk menyimpan metrik kinerja pada setiap lipatan
    accuracy_list, precision_list, recall_list, f1_list = [], [], [], []

    fold = 1

    if verbose:
      print(type(model).__name__, "\n")

    # Loop melalui setiap lipatan cross-validation
    for fold, (train_index, val_index) in enumerate(skf.split(X, y), 1):
        # Memisahkan data menjadi set pelatihan dan pengujian
        X_train, X_val = X.iloc[train_index], X.iloc[val_index]
        y_train, y_val = y.iloc[train_index], y.iloc[val_index]

        # Melatih model pada data pelatihan
        model.fit(X_train, y_train)

        # Membuat prediksi pada data pengujian
        y_pred = model.predict(X_val)

        # Menghitung metrik kinerja
        accuracy = accuracy_score(y_val, y_pred)
        precision = precision_score(y_val, y_pred)
        recall = recall_score(y_val, y_pred)
        f1 = f1_score(y_val, y_pred)

        # Menyimpan metrik kinerja dalam list
        accuracy_list.append(accuracy)
        precision_list.append(precision)
        recall_list.append(recall)
        f1_list.append(f1)

        if verbose:
          # Menampilkan metrik kinerja untuk setiap lipatan
          print(f'===== Fold {fold} =====')
          print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 score: {f1}\n')
          fold += 1

    # Menghitung rata-rata metrik kinerja dari semua lipatan
    mean_accuracy = np.mean(accuracy_list)
    mean_precision = np.mean(precision_list)
    mean_recall = np.mean(recall_list)
    mean_f1 = np.mean(f1_list)

    # Menampilkan rata-rata metrik kinerja
    # print(f'Mean Accuracy: {mean_accuracy}, \nMean Precision: {mean_precision}, \nMean Recall: {mean_recall}, \nMean F1 score: {mean_f1}')

    # Mengembalikan rata-rata metrik kinerja
    return {
        'mean_accuracy': mean_accuracy,
        'mean_precision': mean_precision,
        'mean_recall': mean_recall,
        'mean_f1': mean_f1
    }

# Evaluate Logistic Regression model
evaluate_skf(log_reg, X_train_scaled, y_train)

# Evaluate SVM model
evaluate_skf(svm, X_train_scaled, y_train)

# Evaluate XGBoost model
evaluate_skf(xgb, X_train_scaled, y_train)

"""Tanpa dilakukan hyperparameter tuning, model yang memberikan performa terbaik adalah XGBoost dengan rata-rata skor recall 61.5%

## **Hyperparameter Tuning**
"""

def objective(trial):
    """
    Mendefinisikan ruang pencarian hyperparameter dan mengevaluasi model menggunakan cross-validation
    dalam proses tuning hyperparameter dengan Optuna.

    Parameters:
        trial : optuna.trial.Trial
            Objek trial dari Optuna yang menyediakan interface untuk mendefinisikan ruang pencarian hyperparameter.

    Returns:
        float
            Nilai recall rata-rata dari hasil cross-validation, yang digunakan sebagai metrik objektif
            untuk dioptimalkan oleh Optuna.
    """
    # Definisikan ruang pencarian untuk hyperparameter
    if type(model) == LogisticRegression:
        penalty = trial.suggest_categorical("penalty", ["l1", "l2"])
        solver = 'liblinear' if penalty == 'l1' else 'lbfgs'
        param = {
            "C": trial.suggest_loguniform("C", 1e-5, 100),
            "penalty": penalty,
            "solver": solver
        }
        model.set_params(**param)
    elif type(model) == SVC:
        param = {
            "C": trial.suggest_loguniform("C", 1e-5, 100),
            "kernel": trial.suggest_categorical("kernel", ["linear", "poly", "rbf", "sigmoid"])
        }
        model.set_params(**param)
    elif type(model) == XGBClassifier:
        param = {
            "learning_rate": trial.suggest_loguniform("learning_rate", 1e-5, 1),
            "max_depth": trial.suggest_int("max_depth", 1, 10),
            "n_estimators": trial.suggest_int("n_estimators", 10, 1000),
            "min_child_weight": trial.suggest_loguniform("min_child_weight", 1e-5, 100)
        }
        model.set_params(**param)

    # Evaluasi model dengan cross-validation
    metrics = evaluate_skf(model, X_train_scaled, y_train, verbose=False)

    return metrics['mean_recall']

best_params = {}

for model in [log_reg, svm, xgb]:
    print(f"\nTuning {type(model).__name__}\n")
    study = optuna.create_study(direction="maximize")
    study.optimize(objective, n_trials=100)

    best_params[type(model).__name__] = study.best_params
    print(f"\nBest hyperparameters for {type(model).__name__}: ", study.best_params)

"""## **Tuned Model Final Evaluation**"""

def plotting_confusion_matrix(model, X_test, y_test, title):
    """
    Fungsi ini digunakan untuk membuat visualisasi confusion matrix dari model yang diberikan pada data uji.

    Parameters:
        model : estimator
            Model machine learning yang telah dilatih dan akan dievaluasi.
        X_test : array-like, shape (n_samples, n_features)
            Fitur input untuk data uji.
        y_test : array-like, shape (n_samples,)
            Target output untuk data uji.
        title : str
            Judul yang akan ditampilkan pada plot confusion matrix.

    Returns:
        None
    """

    # Membuat prediksi menggunakan model pada data uji
    y_pred = model.predict(X_test)

    # Menghitung confusion matrix
    cm = confusion_matrix(y_test, y_pred)

    # Membuat plot confusion matrix
    fig, ax = plt.subplots(1, 1, figsize=(8,6))
    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', annot_kws={"fontsize":12}, ax=ax)

    # Mengatur judul dan label sumbu pada plot
    plt.tick_params(axis='both', which='major', labelsize=12)
    ax.set_xlabel('Predicted Labels', fontsize=12)
    ax.set_ylabel('True Labels', fontsize=12)
    ax.set_title('Confusion Matrix ' + title, fontsize=14)
    ax.xaxis.set_ticklabels(['No Diabetes', 'Diabetes'])
    ax.yaxis.set_ticklabels(['No Diabetes', 'Diabetes'])

    # Menampilkan plot confusion matrix
    plt.show()

# Evaluasi akhir pada data uji
for model in [log_reg, svm, xgb]:
    model_name = type(model).__name__
    model.set_params(**best_params[model_name])

    # Latih model dengan hyperparameter terbaik pada seluruh data pelatihan
    model.fit(X_train_scaled, y_train)

    # Prediksi pada data uji
    y_pred = model.predict(X_test_scaled)

    # Hitung metrik kinerja
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    # Tampilkan hasil evaluasi
    print(f"\nEvaluation of {model_name} on test data\n")
    print(f"Accuracy: {accuracy}")
    print(f"Precision: {precision}")
    print(f"Recall: {recall}")
    print(f"F1 score: {f1}")

    # Tampilkan classification report
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

    # Tampilkan confusion matrix
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))

    # Tampilkan confusion matrix dengan plotting
    plotting_confusion_matrix(model, X_test_scaled, y_test, model_name)

"""# **5. Kesimpulan**

1. Algoritma atau model machine learning mana yang paling efektif untuk memprediksi diabetes pada dataset ini?

2. Faktor-faktor apa saja yang paling signifikan dalam memprediksi apakah seseorang akan menderita diabetes?

**JAWAB**

1. Algoritma yang memberikan performa terbaik berdasarkan metrik recall adalah XGBoost menggunakan parameter {'learning_rate': 0.6976367695253294, 'max_depth': 8, 'n_estimators': 253, 'min_child_weight': 0.0005875051517209111} dengan skor recall 70% pada data uji. Hasil confusion matrix juga menunjukkan angka False Negative (FN) yang relatif rendah, yaitu sebanyak 8 dari 77 data.

2. Berdasarkan hasil ANOVA dan matrix korelasi pada tahap EDA, faktor-faktor yang memiliki pengaruh signifikan dalam memprediksi apakah seseorang akan menderita diabetes adalah Glucose, Insulin, BMI dan Age.
"""